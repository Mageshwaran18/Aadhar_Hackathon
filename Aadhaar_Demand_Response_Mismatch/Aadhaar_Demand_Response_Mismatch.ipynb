{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "527623c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8eaec7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biometric columns:\n",
      "['date', 'state', 'district', 'pincode', 'bio_age_5_17', 'bio_age_17_']\n",
      "\n",
      "Demographic columns:\n",
      "['date', 'state', 'district', 'pincode', 'demo_age_5_17', 'demo_age_17_']\n",
      "\n",
      "Enrollment columns:\n",
      "['date', 'state', 'district', 'pincode', 'en_age_0_5', 'en_age_5_17', 'en_age_18_greater']\n"
     ]
    }
   ],
   "source": [
    "# Read the three CSV files\n",
    "biometric_df = pd.read_csv(r'D:\\Project\\Hackathons\\Aadhar_Hackathon\\Documentation\\Normalized_Datasets\\normalized_biometric.csv')\n",
    "demographic_df = pd.read_csv(r'D:\\Project\\Hackathons\\Aadhar_Hackathon\\Documentation\\Normalized_Datasets\\normalized_demographic.csv')\n",
    "enrollment_df = pd.read_csv(r'D:\\Project\\Hackathons\\Aadhar_Hackathon\\Documentation\\Normalized_Datasets\\normalized_enrollment.csv')\n",
    "\n",
    "# Print columns for each dataset\n",
    "print(\"Biometric columns:\")\n",
    "print(biometric_df.columns.tolist())\n",
    "print(\"\\nDemographic columns:\")\n",
    "print(demographic_df.columns.tolist())\n",
    "print(\"\\nEnrollment columns:\")\n",
    "print(enrollment_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eb41b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biometric DataFrame:\n",
      "  Max date: 31-10-2025\n",
      "  Min date: 01-03-2025\n",
      "\n",
      "Demographic DataFrame:\n",
      "  Max date: 31-10-2025\n",
      "  Min date: 01-03-2025\n",
      "\n",
      "Enrollment DataFrame:\n",
      "  Max date: 31-12-2025\n",
      "  Min date: 01-04-2025\n"
     ]
    }
   ],
   "source": [
    "print(\"Biometric DataFrame:\")\n",
    "print(f\"  Max date: {biometric_df['date'].max()}\")\n",
    "print(f\"  Min date: {biometric_df['date'].min()}\")\n",
    "\n",
    "print(\"\\nDemographic DataFrame:\")\n",
    "print(f\"  Max date: {demographic_df['date'].max()}\")\n",
    "print(f\"  Min date: {demographic_df['date'].min()}\")\n",
    "\n",
    "print(\"\\nEnrollment DataFrame:\")\n",
    "print(f\"  Max date: {enrollment_df['date'].max()}\")\n",
    "print(f\"  Min date: {enrollment_df['date'].min()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b197366a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biometric DataFrame (head):\n",
      "         date              state      district  pincode  bio_age_5_17  \\\n",
      "0  01-03-2025            haryana  mahendragarh   123029           280   \n",
      "1  01-03-2025              bihar     madhepura   852121           144   \n",
      "2  01-03-2025  jammu and kashmir        poonch   185101           643   \n",
      "3  01-03-2025              bihar       bhojpur   802158           256   \n",
      "4  01-03-2025         tamil nadu       madurai   625514           271   \n",
      "\n",
      "   bio_age_17_  \n",
      "0          577  \n",
      "1          369  \n",
      "2         1091  \n",
      "3          980  \n",
      "4          815  \n",
      "\n",
      "Demographic DataFrame (head):\n",
      "         date           state    district  pincode  demo_age_5_17  \\\n",
      "0  01-03-2025   uttar_pradesh   gorakhpur   273213             49   \n",
      "1  01-03-2025  andhra_pradesh    chittoor   517132             22   \n",
      "2  01-03-2025         gujarat      rajkot   360006             65   \n",
      "3  01-03-2025  andhra_pradesh  srikakulam   532484             24   \n",
      "4  01-03-2025       rajasthan     udaipur   313801             45   \n",
      "\n",
      "   demo_age_17_  \n",
      "0           529  \n",
      "1           375  \n",
      "2           765  \n",
      "3           314  \n",
      "4           785  \n",
      "\n",
      "Enrollment DataFrame (head):\n",
      "         date          state          district  pincode  en_age_0_5  \\\n",
      "0  02-03-2025      meghalaya  east_khasi_hills   793121          11   \n",
      "1  09-03-2025      karnataka   bengaluru_urban   560043          14   \n",
      "2  09-03-2025  uttar_pradesh      kanpur_nagar   208001          29   \n",
      "3  09-03-2025  uttar_pradesh           aligarh   202133          62   \n",
      "4  09-03-2025      karnataka   bengaluru_urban   560016          14   \n",
      "\n",
      "   en_age_5_17  en_age_18_greater  \n",
      "0           61                 37  \n",
      "1           33                 39  \n",
      "2           82                 12  \n",
      "3           29                 15  \n",
      "4           16                 21  \n"
     ]
    }
   ],
   "source": [
    "print(\"Biometric DataFrame (head):\")\n",
    "print(biometric_df.head())\n",
    "print(\"\\nDemographic DataFrame (head):\")\n",
    "print(demographic_df.head())\n",
    "print(\"\\nEnrollment DataFrame (head):\")\n",
    "print(enrollment_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5225c3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardization complete!\n",
      "Files have been updated successfully.\n",
      "\n",
      "Biometric sample:\n",
      "               state      district\n",
      "0            haryana  mahendragarh\n",
      "1              bihar     madhepura\n",
      "2  jammu_and_kashmir        poonch\n",
      "3              bihar       bhojpur\n",
      "4         tamil_nadu       madurai\n",
      "\n",
      "Demographic sample:\n",
      "            state    district\n",
      "0   uttar_pradesh   gorakhpur\n",
      "1  andhra_pradesh    chittoor\n",
      "2         gujarat      rajkot\n",
      "3  andhra_pradesh  srikakulam\n",
      "4       rajasthan     udaipur\n",
      "\n",
      "Enrollment sample:\n",
      "           state          district\n",
      "0      meghalaya  east_khasi_hills\n",
      "1      karnataka   bengaluru_urban\n",
      "2  uttar_pradesh      kanpur_nagar\n",
      "3  uttar_pradesh           aligarh\n",
      "4      karnataka   bengaluru_urban\n"
     ]
    }
   ],
   "source": [
    "def standardize_dataframes(bio_df, demo_df, enroll_df):\n",
    "    \"\"\"\n",
    "    Standardize state and district columns across three dataframes.\n",
    "    Converts to lowercase, strips whitespace, and replaces spaces with underscores.\n",
    "    \"\"\"\n",
    "    def standardize_columns(df):\n",
    "        df = df.copy()\n",
    "        for col in ['state', 'district']:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].str.lower().str.strip().str.replace(' ', '_')\n",
    "        return df\n",
    "    \n",
    "    bio_df = standardize_columns(bio_df)\n",
    "    demo_df = standardize_columns(demo_df)\n",
    "    enroll_df = standardize_columns(enroll_df)\n",
    "    \n",
    "    return bio_df, demo_df, enroll_df\n",
    "\n",
    "# Apply the function to your dataframes\n",
    "biometric_df, demographic_df, enrollment_df = standardize_dataframes(biometric_df, demographic_df, enrollment_df)\n",
    "\n",
    "# Write the standardized dataframes back to CSV files\n",
    "biometric_df.to_csv(r'D:\\Project\\Hackathons\\Aadhar_Hackathon\\Documentation\\Normalized_Datasets\\normalized_biometric.csv', index=False)\n",
    "demographic_df.to_csv(r'D:\\Project\\Hackathons\\Aadhar_Hackathon\\Documentation\\Normalized_Datasets\\normalized_demographic.csv', index=False)\n",
    "enrollment_df.to_csv(r'D:\\Project\\Hackathons\\Aadhar_Hackathon\\Documentation\\Normalized_Datasets\\normalized_enrollment.csv', index=False)\n",
    "\n",
    "print(\"Standardization complete!\")\n",
    "print(\"Files have been updated successfully.\")\n",
    "print(\"\\nBiometric sample:\")\n",
    "print(biometric_df[['state', 'district']].head())\n",
    "print(\"\\nDemographic sample:\")\n",
    "print(demographic_df[['state', 'district']].head())\n",
    "print(\"\\nEnrollment sample:\")\n",
    "print(enrollment_df[['state', 'district']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a5c9f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "AADHAAR DEMAND-RESPONSE MISMATCH (DRM) ANALYSIS - 2025\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# AADHAAR DEMAND-RESPONSE MISMATCH (DRM) ANALYSIS - 2025\n",
    "# ============================================================================\n",
    "print(\"=\"*80)\n",
    "print(\"AADHAAR DEMAND-RESPONSE MISMATCH (DRM) ANALYSIS - 2025\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "897e54a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP 1-2] Loading datasets...\n",
      "‚úì Biometric records loaded: 1,861,108\n",
      "‚úì Demographic records loaded: 2,045,700\n",
      "‚úì Enrollment records loaded: 1,006,007\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 1 & 2: DATA INGESTION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[STEP 1-2] Loading datasets...\")\n",
    "\n",
    "# Load the three datasets\n",
    "# NOTE: Replace these file paths with your actual file paths\n",
    "biometric_df = pd.read_csv(r'D:\\Project\\Hackathons\\Aadhar_Hackathon\\Documentation\\Normalized_Datasets\\normalized_biometric.csv')\n",
    "demographic_df = pd.read_csv(r'D:\\Project\\Hackathons\\Aadhar_Hackathon\\Documentation\\Normalized_Datasets\\normalized_demographic.csv')\n",
    "enrollment_df = pd.read_csv(r'D:\\Project\\Hackathons\\Aadhar_Hackathon\\Documentation\\Normalized_Datasets\\normalized_enrollment.csv')\n",
    "\n",
    "print(f\"‚úì Biometric records loaded: {len(biometric_df):,}\")\n",
    "print(f\"‚úì Demographic records loaded: {len(demographic_df):,}\")\n",
    "print(f\"‚úì Enrollment records loaded: {len(enrollment_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6540e504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP 3] Validating dates for 2025 compliance...\n",
      "  ‚úì Biometric: 1,861,108 valid 2025 records\n",
      "  ‚úì Demographic: 2,045,700 valid 2025 records\n",
      "  ‚úì Enrollment: 1,006,007 valid 2025 records\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: DATE VALIDATION (2025 CONSTRAINT CHECK)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[STEP 3] Validating dates for 2025 compliance...\")\n",
    "\n",
    "def validate_2025_dates(df, df_name):\n",
    "    \"\"\"Validate and filter data for year 2025\"\"\"\n",
    "    # Parse dates (assuming dd-mm-yyyy format)\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%d-%m-%Y', errors='coerce')\n",
    "    \n",
    "    # Extract year\n",
    "    df['year'] = df['date'].dt.year\n",
    "    \n",
    "    # Count records outside 2025\n",
    "    outside_2025 = df[df['year'] != 2025].shape[0]\n",
    "    \n",
    "    if outside_2025 > 0:\n",
    "        print(f\"  ‚ö† {df_name}: {outside_2025} records outside 2025 - REMOVED\")\n",
    "    \n",
    "    # Filter only 2025 data\n",
    "    df_2025 = df[df['year'] == 2025].copy()\n",
    "    \n",
    "    print(f\"  ‚úì {df_name}: {len(df_2025):,} valid 2025 records\")\n",
    "    \n",
    "    return df_2025\n",
    "\n",
    "biometric_df = validate_2025_dates(biometric_df, \"Biometric\")\n",
    "demographic_df = validate_2025_dates(demographic_df, \"Demographic\")\n",
    "enrollment_df = validate_2025_dates(enrollment_df, \"Enrollment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bbfcf77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP 4] Standardizing geography columns...\n",
      "‚úì Geography columns standardized across all datasets\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 4: STANDARDIZE GEOGRAPHY COLUMNS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[STEP 4] Standardizing geography columns...\")\n",
    "\n",
    "def standardize_geography(df):\n",
    "    \"\"\"Clean and standardize state, district, and pincode\"\"\"\n",
    "    # Convert to lowercase and strip whitespace\n",
    "    df['state'] = df['state'].astype(str).str.lower().str.strip()\n",
    "    df['district'] = df['district'].astype(str).str.lower().str.strip()\n",
    "    df['pincode'] = df['pincode'].astype(str).str.strip()\n",
    "    \n",
    "    # Replace multiple spaces with single space\n",
    "    df['state'] = df['state'].str.replace(r'\\s+', ' ', regex=True)\n",
    "    df['district'] = df['district'].str.replace(r'\\s+', ' ', regex=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "biometric_df = standardize_geography(biometric_df)\n",
    "demographic_df = standardize_geography(demographic_df)\n",
    "enrollment_df = standardize_geography(enrollment_df)\n",
    "\n",
    "print(\"‚úì Geography columns standardized across all datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00565f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP 5] Aggregating data at district level...\n",
      "  ‚Üí Aggregating enrollment data...\n",
      "    ‚úì 767 districts with enrollment data\n",
      "  ‚Üí Aggregating biometric update data...\n",
      "    ‚úì 769 districts with biometric update data\n",
      "  ‚Üí Aggregating demographic update data...\n",
      "    ‚úì 767 districts with demographic update data\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 5: AGGREGATE DATA AT DISTRICT LEVEL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[STEP 5] Aggregating data at district level...\")\n",
    "\n",
    "# ENROLLMENT AGGREGATION\n",
    "print(\"  ‚Üí Aggregating enrollment data...\")\n",
    "enrollment_agg = enrollment_df.groupby(['state', 'district']).agg({\n",
    "    'en_age_0_5': 'sum',\n",
    "    'en_age_5_17': 'sum',\n",
    "    'en_age_18_greater': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "enrollment_agg['total_enrollment'] = (\n",
    "    enrollment_agg['en_age_0_5'] + \n",
    "    enrollment_agg['en_age_5_17'] + \n",
    "    enrollment_agg['en_age_18_greater']\n",
    ")\n",
    "\n",
    "print(f\"    ‚úì {len(enrollment_agg)} districts with enrollment data\")\n",
    "\n",
    "# BIOMETRIC UPDATE AGGREGATION\n",
    "print(\"  ‚Üí Aggregating biometric update data...\")\n",
    "biometric_agg = biometric_df.groupby(['state', 'district']).agg({\n",
    "    'bio_age_5_17': 'sum',\n",
    "    'bio_age_17_': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "biometric_agg['total_biometric_updates'] = (\n",
    "    biometric_agg['bio_age_5_17'] + \n",
    "    biometric_agg['bio_age_17_']\n",
    ")\n",
    "\n",
    "print(f\"    ‚úì {len(biometric_agg)} districts with biometric update data\")\n",
    "\n",
    "# DEMOGRAPHIC UPDATE AGGREGATION\n",
    "print(\"  ‚Üí Aggregating demographic update data...\")\n",
    "demographic_agg = demographic_df.groupby(['state', 'district']).agg({\n",
    "    'demo_age_5_17': 'sum',\n",
    "    'demo_age_17_': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "demographic_agg['total_demographic_updates'] = (\n",
    "    demographic_agg['demo_age_5_17'] + \n",
    "    demographic_agg['demo_age_17_']\n",
    ")\n",
    "\n",
    "print(f\"    ‚úì {len(demographic_agg)} districts with demographic update data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbc1bbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP 6] Merging all aggregated data using INNER JOIN...\n",
      "‚úì Merged dataset created with 732 districts\n",
      "‚úì Only districts with enrollment, biometric, and demographic activity included\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 6: MERGE ALL AGGREGATED DATA (INNER JOIN - CORRECT APPROACH)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[STEP 6] Merging all aggregated data using INNER JOIN...\")\n",
    "\n",
    "# Merge Enrollment and Biometric data\n",
    "merged_df = enrollment_agg[['state', 'district', 'total_enrollment']].merge(\n",
    "    biometric_agg[['state', 'district', 'total_biometric_updates']],\n",
    "    on=['state', 'district'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Merge with Demographic data\n",
    "merged_df = merged_df.merge(\n",
    "    demographic_agg[['state', 'district', 'total_demographic_updates']],\n",
    "    on=['state', 'district'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(f\"‚úì Merged dataset created with {len(merged_df)} districts\")\n",
    "print(\"‚úì Only districts with enrollment, biometric, and demographic activity included\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1f4e298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP 6A] Validating missing and zero values after merge...\n",
      "\n",
      "Missing values per column:\n",
      "total_enrollment             0\n",
      "total_biometric_updates      0\n",
      "total_demographic_updates    0\n",
      "dtype: int64\n",
      "\n",
      "Zero-value counts per column:\n",
      "total_enrollment             0\n",
      "total_biometric_updates      0\n",
      "total_demographic_updates    0\n",
      "dtype: int64\n",
      "\n",
      "Rows with at least one zero value: 0\n",
      "‚úì Step 6 and 6A completed successfully\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 6A: VALIDATE ZERO / MISSING VALUES AFTER MERGE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[STEP 6A] Validating missing and zero values after merge...\")\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = merged_df[\n",
    "    ['total_enrollment', 'total_biometric_updates', 'total_demographic_updates']\n",
    "].isna().sum()\n",
    "\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Check for zero values\n",
    "zero_values = (merged_df[\n",
    "    ['total_enrollment', 'total_biometric_updates', 'total_demographic_updates']\n",
    "] == 0).sum()\n",
    "\n",
    "print(\"\\nZero-value counts per column:\")\n",
    "print(zero_values)\n",
    "\n",
    "# Identify rows with any zero values (for review, not removal)\n",
    "zero_value_rows = merged_df[\n",
    "    (merged_df['total_enrollment'] == 0) |\n",
    "    (merged_df['total_biometric_updates'] == 0) |\n",
    "    (merged_df['total_demographic_updates'] == 0)\n",
    "]\n",
    "\n",
    "print(f\"\\nRows with at least one zero value: {len(zero_value_rows)}\")\n",
    "\n",
    "# Final safety fill (harmless with INNER JOIN)\n",
    "merged_df = merged_df.fillna(0)\n",
    "\n",
    "print(\"‚úì Step 6 and 6A completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59fdcf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP 7] Computing total update load...\n",
      "‚úì Total updates calculated for all districts\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 7: COMPUTE TOTAL UPDATE LOAD\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[STEP 7] Computing total update load...\")\n",
    "\n",
    "merged_df['total_updates'] = (\n",
    "    merged_df['total_biometric_updates'] + \n",
    "    merged_df['total_demographic_updates']\n",
    ")\n",
    "\n",
    "print(f\"‚úì Total updates calculated for all districts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26b68a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP 8] Computing total Aadhaar activity...\n",
      "‚úì Total activity calculated\n",
      "‚úì Active districts: 732\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 8: COMPUTE TOTAL AADHAAR ACTIVITY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[STEP 8] Computing total Aadhaar activity...\")\n",
    "\n",
    "merged_df['total_activity'] = (\n",
    "    merged_df['total_enrollment'] + \n",
    "    merged_df['total_updates']\n",
    ")\n",
    "\n",
    "# Remove districts with zero activity (if any)\n",
    "active_districts = merged_df[merged_df['total_activity'] > 0].copy()\n",
    "\n",
    "print(f\"‚úì Total activity calculated\")\n",
    "print(f\"‚úì Active districts: {len(active_districts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0686b9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP 9] Calculating DRM Score...\n",
      "‚úì DRM Score calculated for all active districts\n",
      "  ‚Üí DRM Score Range: [-0.445, 0.996]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 9: CALCULATE DRM SCORE (CORE INNOVATION)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[STEP 9] Calculating DRM Score...\")\n",
    "\n",
    "active_districts['drm_score'] = (\n",
    "    (active_districts['total_updates'] - active_districts['total_enrollment']) / \n",
    "    active_districts['total_activity']\n",
    ")\n",
    "\n",
    "print(\"‚úì DRM Score calculated for all active districts\")\n",
    "print(f\"  ‚Üí DRM Score Range: [{active_districts['drm_score'].min():.3f}, {active_districts['drm_score'].max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b5687e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP 10A] Computing DRM percentile thresholds...\n",
      "DRM Percentile Thresholds:\n",
      "  20th percentile: 0.882\n",
      "  40th percentile: 0.911\n",
      "  60th percentile: 0.930\n",
      "  80th percentile: 0.947\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 10: CLASSIFY DISTRICTS\n",
    "# ============================================================================\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 10A: COMPUTE DATA-DRIVEN DRM THRESHOLDS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[STEP 10A] Computing DRM percentile thresholds...\")\n",
    "\n",
    "p20 = active_districts['drm_score'].quantile(0.20)\n",
    "p40 = active_districts['drm_score'].quantile(0.40)\n",
    "p60 = active_districts['drm_score'].quantile(0.60)\n",
    "p80 = active_districts['drm_score'].quantile(0.80)\n",
    "\n",
    "print(f\"DRM Percentile Thresholds:\")\n",
    "print(f\"  20th percentile: {p20:.3f}\")\n",
    "print(f\"  40th percentile: {p40:.3f}\")\n",
    "print(f\"  60th percentile: {p60:.3f}\")\n",
    "print(f\"  80th percentile: {p80:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b3ed6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 10B: SEMANTICALLY CORRECT DISTRICT CLASSIFICATION\n",
    "# ============================================================================\n",
    "\n",
    "def classify_district_pressure(drm):\n",
    "    \"\"\"\n",
    "    Classify districts based on relative Aadhaar update pressure.\n",
    "    Labels reflect degree of update dominance (not absolute enrollment surplus).\n",
    "    \"\"\"\n",
    "    if drm >= p80:\n",
    "        return 'Very High Update Pressure'\n",
    "    elif drm >= p60:\n",
    "        return 'High Update Pressure'\n",
    "    elif drm >= p40:\n",
    "        return 'Moderate Update Pressure'\n",
    "    elif drm >= p20:\n",
    "        return 'Low Update Pressure'\n",
    "    else:\n",
    "        return 'Very Low Update Pressure'\n",
    "\n",
    "active_districts['category'] = active_districts['drm_score'].apply(classify_district_pressure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6dea3ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì District Classification Complete (Update Pressure Levels):\n",
      "  ‚Üí Very High Update Pressure: 147 districts (20.1%)\n",
      "  ‚Üí Very Low Update Pressure: 147 districts (20.1%)\n",
      "  ‚Üí High Update Pressure: 146 districts (19.9%)\n",
      "  ‚Üí Moderate Update Pressure: 146 districts (19.9%)\n",
      "  ‚Üí Low Update Pressure: 146 districts (19.9%)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 10C: CATEGORY DISTRIBUTION REPORTING\n",
    "# ============================================================================\n",
    "\n",
    "category_counts = active_districts['category'].value_counts()\n",
    "\n",
    "print(\"\\n‚úì District Classification Complete (Update Pressure Levels):\")\n",
    "for cat, count in category_counts.items():\n",
    "    pct = (count / len(active_districts)) * 100\n",
    "    print(f\"  ‚Üí {cat}: {count} districts ({pct:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ea25416b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP 11] Ranking districts by update pressure...\n",
      "‚úì District rankings created\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 11: RANK DISTRICTS BY UPDATE PRESSURE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[STEP 11] Ranking districts by update pressure...\")\n",
    "\n",
    "# Sort districts by DRM score (descending = higher update pressure)\n",
    "ranked_df = active_districts.sort_values(\n",
    "    'drm_score', ascending=False\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Top 15 districts with VERY HIGH update pressure\n",
    "top_very_high_pressure = ranked_df[\n",
    "    ranked_df['category'] == 'Very High Update Pressure'\n",
    "].head(15)\n",
    "\n",
    "# Top 15 districts with VERY LOW update pressure\n",
    "top_very_low_pressure = ranked_df[\n",
    "    ranked_df['category'] == 'Very Low Update Pressure'\n",
    "].tail(15)\n",
    "\n",
    "print(\"‚úì District rankings created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "74ff6cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP 12] Generating summary statistics...\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 12: GENERATE SUMMARY STATISTICS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[STEP 12] Generating summary statistics...\")\n",
    "\n",
    "summary_stats = {\n",
    "    'total_districts_analyzed': len(active_districts),\n",
    "    'total_enrollments_2025': int(active_districts['total_enrollment'].sum()),\n",
    "    'total_biometric_updates_2025': int(active_districts['total_biometric_updates'].sum()),\n",
    "    'total_demographic_updates_2025': int(active_districts['total_demographic_updates'].sum()),\n",
    "    'total_updates_2025': int(active_districts['total_updates'].sum()),\n",
    "    'total_activity_2025': int(active_districts['total_activity'].sum())\n",
    "}\n",
    "\n",
    "# Category distribution\n",
    "category_counts = active_districts['category'].value_counts(normalize=True) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "01b0fa09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ANALYSIS RESULTS - AADHAAR DRM 2025\n",
      "================================================================================\n",
      "\n",
      "üìä OVERALL SUMMARY\n",
      "--------------------------------------------------------------------------------\n",
      "Total Districts Analyzed: 732\n",
      "Total Enrollments (2025): 5,257,909\n",
      "Total Biometric Updates (2025): 67,445,679\n",
      "Total Demographic Updates (2025): 47,664,654\n",
      "Total Updates (2025): 115,110,333\n",
      "Total Aadhaar Activity (2025): 120,368,242\n",
      "\n",
      "üéØ DISTRICT CLASSIFICATION BY UPDATE PRESSURE\n",
      "--------------------------------------------------------------------------------\n",
      "Very High Update Pressure: 20.1%\n",
      "Very Low Update Pressure: 20.1%\n",
      "High Update Pressure: 19.9%\n",
      "Moderate Update Pressure: 19.9%\n",
      "Low Update Pressure: 19.9%\n",
      "\n",
      "üî¥ TOP 15 DISTRICTS ‚Äî VERY HIGH UPDATE PRESSURE\n",
      "--------------------------------------------------------------------------------\n",
      "Rank   State                District                  DRM      Updates      Enrollments \n",
      "--------------------------------------------------------------------------------\n",
      "1      rajasthan            beawar                    0.996    518          1           \n",
      "2      rajasthan            balotra                   0.996    509          1           \n",
      "3      rajasthan            salumbar                  0.991    214          1           \n",
      "4      west_bengal          paschim_bardhaman         0.988    220,436      1,276       \n",
      "5      manipur              thoubal                   0.982    115,287      1,067       \n",
      "6      manipur              imphal_east               0.981    115,294      1,132       \n",
      "7      mizoram              serchhip                  0.980    10,059       102         \n",
      "8      manipur              imphal_west               0.980    120,661      1,236       \n",
      "9      chhattisgarh         balod                     0.976    140,949      1,678       \n",
      "10     maharashtra          gadchiroli                0.976    193,363      2,374       \n",
      "11     maharashtra          wardha                    0.975    156,801      1,953       \n",
      "12     andhra_pradesh       srikakulam                0.974    328,306      4,300       \n",
      "13     maharashtra          ratnagiri                 0.973    192,198      2,603       \n",
      "14     maharashtra          bhandara                  0.973    140,098      1,903       \n",
      "15     punjab               mansa                     0.973    82,594       1,124       \n",
      "\n",
      "üü¢ TOP 15 DISTRICTS ‚Äî VERY LOW UPDATE PRESSURE (CAPACITY BUFFER)\n",
      "--------------------------------------------------------------------------------\n",
      "Rank   State                District                  DRM      Updates      Enrollments \n",
      "--------------------------------------------------------------------------------\n",
      "15     meghalaya            west_garo_hills           0.506    48,440       15,875      \n",
      "14     assam                west_karbi_anglong        0.440    4,843        1,884       \n",
      "13     nagaland             shamator                  0.419    603          247         \n",
      "12     meghalaya            south_west_garo_hills     0.419    12,097       4,956       \n",
      "11     meghalaya            south_west_khasi_hills    0.407    8,172        3,446       \n",
      "10     meghalaya            north_garo_hills          0.246    5,075        3,069       \n",
      "9      meghalaya            east_garo_hills           0.200    9,069        6,052       \n",
      "8      meghalaya            ri_bhoi                   0.156    12,740       9,308       \n",
      "7      meghalaya            east_khasi_hills          0.129    37,364       28,812      \n",
      "6      meghalaya            east_jaintia_hills        0.092    6,176        5,133       \n",
      "5      mizoram              khawzawl                  0.089    43           36          \n",
      "4      meghalaya            south_garo_hills          0.087    5,289        4,441       \n",
      "3      meghalaya            west_jaintia_hills        0.072    13,645       11,820      \n",
      "2      meghalaya            west_khasi_hills          0.022    16,598       15,898      \n",
      "1      meghalaya            eastern_west_khasi_hills  -0.445   314          818         \n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DISPLAY RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS RESULTS - AADHAAR DRM 2025\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìä OVERALL SUMMARY\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Total Districts Analyzed: {summary_stats['total_districts_analyzed']:,}\")\n",
    "print(f\"Total Enrollments (2025): {summary_stats['total_enrollments_2025']:,}\")\n",
    "print(f\"Total Biometric Updates (2025): {summary_stats['total_biometric_updates_2025']:,}\")\n",
    "print(f\"Total Demographic Updates (2025): {summary_stats['total_demographic_updates_2025']:,}\")\n",
    "print(f\"Total Updates (2025): {summary_stats['total_updates_2025']:,}\")\n",
    "print(f\"Total Aadhaar Activity (2025): {summary_stats['total_activity_2025']:,}\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\nüéØ DISTRICT CLASSIFICATION BY UPDATE PRESSURE\")\n",
    "print(\"-\" * 80)\n",
    "for cat, pct in category_counts.items():\n",
    "    print(f\"{cat}: {pct:.1f}%\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\nüî¥ TOP 15 DISTRICTS ‚Äî VERY HIGH UPDATE PRESSURE\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Rank':<6} {'State':<20} {'District':<25} {'DRM':<8} {'Updates':<12} {'Enrollments':<12}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, row in top_very_high_pressure.iterrows():\n",
    "    print(f\"{i+1:<6} {row['state'][:19]:<20} {row['district'][:24]:<25} \"\n",
    "          f\"{row['drm_score']:<8.3f} {int(row['total_updates']):<12,} {int(row['total_enrollment']):<12,}\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\nüü¢ TOP 15 DISTRICTS ‚Äî VERY LOW UPDATE PRESSURE (CAPACITY BUFFER)\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Rank':<6} {'State':<20} {'District':<25} {'DRM':<8} {'Updates':<12} {'Enrollments':<12}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, row in top_very_low_pressure.iterrows():\n",
    "    print(f\"{len(active_districts)-i:<6} {row['state'][:19]:<20} {row['district'][:24]:<25} \"\n",
    "          f\"{row['drm_score']:<8.3f} {int(row['total_updates']):<12,} {int(row['total_enrollment']):<12,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5018bc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí° KEY INSIGHTS\n",
      "--------------------------------------------------------------------------------\n",
      "1. National Update-to-Enrollment Ratio (2025): 21.89\n",
      "2. Aadhaar activity in 2025 is update-dominant across all districts.\n",
      "3. Significant variation exists in the degree of update pressure, enabling targeted intervention.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# KEY INSIGHTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüí° KEY INSIGHTS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "update_to_enrollment_ratio = (\n",
    "    summary_stats['total_updates_2025'] /\n",
    "    summary_stats['total_enrollments_2025']\n",
    "    if summary_stats['total_enrollments_2025'] > 0 else 0\n",
    ")\n",
    "\n",
    "print(f\"1. National Update-to-Enrollment Ratio (2025): {update_to_enrollment_ratio:.2f}\")\n",
    "print(\"2. Aadhaar activity in 2025 is update-dominant across all districts.\")\n",
    "print(\"3. Significant variation exists in the degree of update pressure, enabling targeted intervention.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fc4b68d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÅ EXPORTING RESULTS\n",
      "--------------------------------------------------------------------------------\n",
      "‚úì Full analysis exported\n",
      "‚úì Very high update pressure districts exported\n",
      "‚úì Very low update pressure districts exported\n",
      "‚úì Summary statistics exported\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# EXPORT RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüìÅ EXPORTING RESULTS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "active_districts.to_csv('aadhaar_drm_analysis_2025_full.csv', index=False)\n",
    "print(\"‚úì Full analysis exported\")\n",
    "\n",
    "top_very_high_pressure.to_csv(\n",
    "    'aadhaar_drm_very_high_update_pressure_2025.csv', index=False\n",
    ")\n",
    "print(\"‚úì Very high update pressure districts exported\")\n",
    "\n",
    "top_very_low_pressure.to_csv(\n",
    "    'aadhaar_drm_very_low_update_pressure_2025.csv', index=False\n",
    ")\n",
    "print(\"‚úì Very low update pressure districts exported\")\n",
    "\n",
    "summary_df = pd.DataFrame([summary_stats])\n",
    "summary_df.to_csv('aadhaar_drm_summary_2025.csv', index=False)\n",
    "print(\"‚úì Summary statistics exported\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17ba353",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
